# Contribuir a IBioML

Â¡Gracias por tu interÃ©s en contribuir a IBioML! Este proyecto se beneficia enormemente de las contribuciones de la comunidad.

## ğŸš€ Formas de Contribuir

### ğŸ› Reportar Bugs
- Usa el [sistema de issues](https://github.com/tuusuario/IBioML/issues) de GitHub
- Incluye informaciÃ³n detallada sobre el error
- Proporciona un ejemplo mÃ­nimo reproducible

### ğŸ’¡ Sugerir Nuevas CaracterÃ­sticas
- Abre un issue describiendo la caracterÃ­stica
- Explica el caso de uso y beneficios
- Discute la implementaciÃ³n propuesta

### ğŸ“ Mejorar DocumentaciÃ³n
- Corregir errores tipogrÃ¡ficos
- Agregar ejemplos o aclaraciones
- Traducir contenido

### ğŸ”§ Contribuir CÃ³digo
- Implementar nuevas caracterÃ­sticas
- Corregir bugs
- Mejorar rendimiento
- Agregar tests

## ğŸ› ï¸ ConfiguraciÃ³n del Entorno de Desarrollo

### 1. Fork y Clone

```bash
# Fork el repositorio en GitHub, luego:
git clone https://github.com/tu-usuario/IBioML.git
cd IBioML
```

### 2. Configurar Entorno Virtual

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar en modo desarrollo
pip install -e ".[dev]"
```

### 3. Instalar Dependencias de Desarrollo

```bash
pip install pytest black flake8 mypy pre-commit mkdocs-material
```

### 4. Configurar Pre-commit Hooks

```bash
pre-commit install
```

## ğŸ“‹ GuÃ­as de ContribuciÃ³n

### Estilo de CÃ³digo

IBioML sigue las convenciones de Python (PEP 8) con algunas extensiones:

```python
# Usar type hints
def preprocess_data(
    file_path: str,
    file_name_to_save: str,
    bins_before: int = 5,
    bins_after: int = 5
) -> None:
    """
    Preprocesa datos neuronales.
    
    Args:
        file_path: Ruta al archivo .mat
        file_name_to_save: Nombre base para archivos de salida
        bins_before: Ventana temporal hacia atrÃ¡s
        bins_after: Ventana temporal hacia adelante
    """
    pass

# Nombres descriptivos
def calculate_r2_score(predictions: np.ndarray, targets: np.ndarray) -> float:
    """Calcula el coeficiente de determinaciÃ³n RÂ²."""
    pass

# DocumentaciÃ³n clara en espaÃ±ol para funciones pÃºblicas
class MLPModel(nn.Module):
    """
    PerceptrÃ³n multicapa para neurodecodificaciÃ³n.
    
    Esta clase implementa una red neuronal feedforward con mÃºltiples
    capas ocultas y dropout para regularizaciÃ³n.
    """
    pass
```

### Formateo AutomÃ¡tico

```bash
# Formatear cÃ³digo con black
black ibioml/

# Verificar estilo con flake8
flake8 ibioml/

# Verificar tipos con mypy
mypy ibioml/
```

### Estructura de Commits

Usa el formato de [Conventional Commits](https://www.conventionalcommits.org/):

```
tipo(Ã¡mbito): descripciÃ³n breve

DescripciÃ³n mÃ¡s detallada si es necesario.

Fixes #123
```

Tipos principales:
- `feat`: Nueva caracterÃ­stica
- `fix`: CorrecciÃ³n de bug
- `docs`: Cambios en documentaciÃ³n
- `style`: Cambios de formato (sin afectar lÃ³gica)
- `refactor`: RefactorizaciÃ³n de cÃ³digo
- `test`: Agregar o modificar tests
- `chore`: Tareas de mantenimiento

Ejemplos:
```
feat(models): agregar soporte para modelos transformer

docs(preprocessing): mejorar ejemplos de uso

fix(tuner): corregir error en validaciÃ³n cruzada anidada
```

## ğŸ§ª Testing

### Ejecutar Tests

```bash
# Todos los tests
pytest

# Tests especÃ­ficos
pytest tests/test_models.py

# Con cobertura
pytest --cov=ibioml
```

### Escribir Tests

```python
import pytest
import numpy as np
from ibioml.models import MLPModel

class TestMLPModel:
    """Tests para el modelo MLP."""
    
    def test_model_creation(self):
        """Test bÃ¡sico de creaciÃ³n del modelo."""
        model = MLPModel(
            input_size=100,
            hidden_size=50,
            output_size=1,
            num_layers=2,
            dropout=0.1
        )
        assert model.input_size == 100
        assert model.output_size == 1
    
    def test_forward_pass(self):
        """Test del forward pass."""
        model = MLPModel(100, 50, 1, 2, 0.1)
        x = torch.randn(10, 100)
        output = model(x)
        assert output.shape == (10, 1)
    
    @pytest.mark.parametrize("batch_size", [1, 16, 32])
    def test_different_batch_sizes(self, batch_size):
        """Test con diferentes tamaÃ±os de lote."""
        model = MLPModel(100, 50, 1, 2, 0.1)
        x = torch.randn(batch_size, 100)
        output = model(x)
        assert output.shape == (batch_size, 1)
```

## ğŸ“š DocumentaciÃ³n

### Estructura de DocumentaciÃ³n

```
docs/
â”œâ”€â”€ index.md              # PÃ¡gina principal
â”œâ”€â”€ installation.md       # GuÃ­a de instalaciÃ³n
â”œâ”€â”€ preprocessing.md       # Preprocesamiento
â”œâ”€â”€ experiments.md         # ConfiguraciÃ³n de experimentos
â”œâ”€â”€ visualization.md       # VisualizaciÃ³n
â”œâ”€â”€ api/                   # DocumentaciÃ³n de API
â”‚   â”œâ”€â”€ models.md
â”‚   â”œâ”€â”€ preprocessing.md
â”‚   â””â”€â”€ training.md
â””â”€â”€ examples/              # Tutoriales y ejemplos
    â”œâ”€â”€ basic_tutorial.md
    â””â”€â”€ advanced_usage.md
```

### Escribir DocumentaciÃ³n

```markdown
# TÃ­tulo de la SecciÃ³n

DescripciÃ³n breve y clara de quÃ© hace esta funcionalidad.

## Uso BÃ¡sico

```python
# Ejemplo de cÃ³digo simple
from ibioml.models import MLPModel

model = MLPModel(input_size=100, hidden_size=50, output_size=1)
```

## ParÃ¡metros

| ParÃ¡metro | Tipo | DescripciÃ³n |
|-----------|------|-------------|
| `input_size` | int | NÃºmero de caracterÃ­sticas de entrada |
| `hidden_size` | int | Neuronas en capas ocultas |

!!! tip "RecomendaciÃ³n"
    Para mejores resultados, usa `hidden_size` entre 64 y 512.

!!! warning "Advertencia"
    Valores muy altos de `dropout` pueden degradar el rendimiento.
```

### Generar DocumentaciÃ³n Localmente

```bash
# Instalar dependencias
pip install mkdocs-material mkdocstrings[python]

# Servir documentaciÃ³n localmente
mkdocs serve

# Compilar documentaciÃ³n
mkdocs build
```

## ğŸ”„ Proceso de Pull Request

### 1. Preparar el PR

```bash
# Crear rama para tu caracterÃ­stica
git checkout -b feat/nueva-caracteristica

# Hacer cambios y commits
git add .
git commit -m "feat(models): agregar modelo transformer"

# Push a tu fork
git push origin feat/nueva-caracteristica
```

### 2. Crear Pull Request

1. Ve a GitHub y crea un PR desde tu rama
2. Usa la plantilla de PR (si existe)
3. Describe claramente los cambios
4. Relaciona con issues relevantes

### 3. Plantilla de PR

```markdown
## DescripciÃ³n

DescripciÃ³n breve de los cambios realizados.

## Tipo de cambio

- [ ] Bug fix (cambio que corrige un issue)
- [ ] Nueva caracterÃ­stica (cambio que agrega funcionalidad)
- [ ] Breaking change (cambio que rompe compatibilidad)
- [ ] DocumentaciÃ³n

## Testing

- [ ] Tests existentes pasan
- [ ] AgreguÃ© tests para nuevos cambios
- [ ] Tests cubren casos edge

## Checklist

- [ ] Mi cÃ³digo sigue el estilo del proyecto
- [ ] AgreguÃ© documentaciÃ³n para nuevas caracterÃ­sticas
- [ ] Los tests pasan localmente
- [ ] ActualicÃ© CHANGELOG.md (si aplica)

## Issues relacionados

Fixes #123
```

### 4. RevisiÃ³n de CÃ³digo

- Responde constructivamente a los comentarios
- Haz los cambios solicitados
- MantÃ©n la discusiÃ³n profesional y enfocada

## ğŸ—ï¸ Arquitectura del Proyecto

### Estructura de Carpetas

```
ibioml/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ models.py              # Modelos de ML
â”œâ”€â”€ preprocessing.py       # Preprocesamiento de datos
â”œâ”€â”€ trainer.py            # LÃ³gica de entrenamiento
â”œâ”€â”€ tuner.py              # OptimizaciÃ³n de hiperparÃ¡metros
â”œâ”€â”€ plots.py              # Funciones de visualizaciÃ³n
â”œâ”€â”€ utils/                # Utilidades
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_scaler.py
â”‚   â”œâ”€â”€ evaluators.py
â”‚   â”œâ”€â”€ model_factory.py
â”‚   â””â”€â”€ preprocessing_funcs.py
â””â”€â”€ results/              # GestiÃ³n de resultados (nueva)
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ experiment_results.py
    â””â”€â”€ visualizer.py
```

### Principios de DiseÃ±o

1. **Modularidad**: Cada mÃ³dulo tiene una responsabilidad clara
2. **Extensibilidad**: FÃ¡cil agregar nuevos modelos y funcionalidades
3. **Usabilidad**: API simple e intuitiva
4. **Robustez**: Manejo de errores y validaciÃ³n de entrada
5. **Rendimiento**: Optimizado para datasets grandes

## ğŸ¯ Ãreas que Necesitan Contribuciones

### Alta Prioridad

- [ ] Soporte para modelos Transformer
- [ ] Mejoras en visualizaciÃ³n interactiva
- [ ] OptimizaciÃ³n de memoria para datasets grandes
- [ ] IntegraciÃ³n con MLflow/Weights & Biases
- [ ] Tests adicionales (especialmente integration tests)

### Media Prioridad

- [ ] Soporte para mÃ¡s formatos de datos (HDF5, Parquet)
- [ ] AnÃ¡lisis estadÃ­sticos avanzados
- [ ] ExportaciÃ³n de modelos a ONNX
- [ ] ParalelizaciÃ³n de experimentos
- [ ] DocumentaciÃ³n en inglÃ©s

### Baja Prioridad

- [ ] Interfaz grÃ¡fica web
- [ ] Soporte para modelos probabilÃ­sticos
- [ ] IntegraciÃ³n con cloud providers
- [ ] Mobile/edge deployment

## ğŸ¤ ComunicaciÃ³n

### Canales de ComunicaciÃ³n

- **Issues de GitHub**: Para bugs y feature requests
- **Discussions**: Para preguntas generales y discusiÃ³n
- **Email**: [jiponce@ibioba-mpsp-conicet.gov.ar](mailto:jiponce@ibioba-mpsp-conicet.gov.ar)

### CÃ³digo de Conducta

- SÃ© respetuoso y constructivo
- Acepta feedback de manera positiva
- Ayuda a otros contribuidores
- MantÃ©n discusiones tÃ©cnicas enfocadas

## ğŸ“œ Licencia

Al contribuir a IBioML, aceptas que tus contribuciones sean licenciadas bajo la misma licencia MIT del proyecto.

---

Â¡Gracias por contribuir a IBioML! ğŸš€
